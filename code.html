<!DOCTYPE html>
<!-- saved from url=(0034)https://www.cc.gatech.edu/~dbatra/ -->
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
 
 <meta name="description" content="Senior Research Scientist (AI2) and Affiliate Associate Professor (University of Washington)">
 <meta name="og:description" content="Senior Research Scientist (AI2) and Affiliate Associate Professor (University of Washington)">
 <title>Roozbeh Mottaghi</title>
 <link rel="stylesheet" href="./misc/mystyle.css">
 <link rel="stylesheet" href="./misc/pygments.css">
</head>

<body>

<!-- Header -->
<header>
<h2><a href="./index.html">Roozbeh Mottaghi</a></h2>
<nav>
<ul>
 <li><a href="./index.html">Home</a></li>
  <li><a href="./index.html#pubs">Publications</a></li>
  <li><a href="./code.html">Code</a></li>
  <li><a href="./misc/CV.pdf">CV</a></li>
</ul>
</nav>
</header>

<section>
<h3 style="text-align: center">Joint model-based and model-free RL for Visual Reaction</h3>

<p>
PyTorch implementation of our CVPR 2020 paper <i>Visual Reaction: Learning To Play Catch With Your Drone</i>.
</p>

<a href="https://github.com/KuoHaoZeng/Visual_Reaction">Github page</a>
</section>

<section>
<h3 style="text-align: center">Imitation learning for language instruction following</h3>

<p>
PyTorch implementation of our CVPR 2020 paper <i>ALFRED: A Benchmark for Interpreting Grounded Instructions for Everyday Tasks</i>.
</p>

<a href="https://github.com/askforalfred/alfred">Github page</a>
</section>



<section>
<h3 style="text-align: center">Meta-learning for self-adapative navigation</h3>

<p>
PyTorch implementation of our CVPR 2019 paper <i>Learning to Learn how to Learn: Self-Adaptive Visual Navigation using Meta-Learning</i> and our ICLR 2019 paper <i>Visual Semantic Navigation using Scene Priors</i>.
</p>

<a href="https://github.com/allenai/savn">Github page</a>
</section>

<section>
<h3 style="text-align: center">Dog behavior modeling</h3>

<p>
Torch implementation of our CVPR 2018 paper <i>Who Let The Dogs Out? Modeling Dog Behavior From Visual Data</i>.
</p>

<a href="https://github.com/ehsanik/dogTorch">Github page</a>
</section>

<section>
<h3 style="text-align: center">Occlusion reasoning</h3>

<p>
Torch implementation of our CVPR 2018 paper <i>SeGAN: Segmenting and Generating the Invisible</i>.
</p>

<a href="https://github.com/ehsanik/SeGAN">Github page</a>
</section>

<section>
<h3 style="text-align: center">Physics-based prediction</h3>

<p>
Torch implementation of our ECCV 2016 paper <i>"What happens if..." Learning to Predict the Effect of Forces in Images</i> and our CVPR 2016 paper <i>Newtonian Image Understanding: Unfolding the Dynamics of Objects in Static Images</i>.
</p>

<a href="https://github.com/allenai/newtonian">Github page</a> for Newtonian Image Understanding <br>
<a href="https://github.com/allenai/forces">Github page</a> for What Happens if
</section>

<!-- Footer -->
<footer>
<h4>Â© Roozbeh Mottaghi</h4>
<h6>(Adopted the template from <a href="https://www.cc.gatech.edu/~dbatra/">Dhruv Batra</a>'s website)</h6>
</footer>



</body></html>