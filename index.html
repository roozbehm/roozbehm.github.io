<!DOCTYPE html>
<!-- saved from url=(0034)https://www.cc.gatech.edu/~dbatra/ -->
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
 
 <meta name="description" content="Research Manager (AI2) and Affiliate Associate Professor (University of Washington)">
 <meta name="og:description" content="Research Manager (AI2) and Affiliate Associate Professor (University of Washington)">
 <meta name="robots" content="all">
 <title>Roozbeh Mottaghi's Webpage</title>
 <link rel="stylesheet" href="./misc/mystyle.css">
 <link rel="stylesheet" href="./misc/pygments.css">
</head>

<body>

<!-- Header -->
<header>
<h2><a href="index.html">Roozbeh Mottaghi</a></h2>
<nav>
<ul>
 <li><a href="index.html">Home</a></li>
  <li><a href="#pubs">Publications</a></li>
  <li><a href="code.html">Code</a></li>
  <li><a href="misc/CV.pdf">CV</a></li>
</ul>
</nav>
</header>

<!-- Affiliations + Contact -->
<section style="height: 250px;">
<div class ="profile">
	<img src="./images/profile_roozbehM.jpg" align="left" width="230" style="margin-top:5px; margin-right:81px" alt="me">
	<div>
	<b>Roozbeh Mottaghi</b>
	<br><br>
	Research Manager <br>
	<a href="http://prior.allenai.org">PRIOR team</a> <br>
	<a href="http://allenai.org">Allen Institute for AI (AI2)</a> <br>

	<br>
	Affiliate Associate Professor <br>
	<a href="https://www.cs.washington.edu/">Paul G. Allen School of Computer Science & Engineering</a> <br>
	<a href="https://www.washington.edu/">University of Washington</a> <br>

	<br>
	Email: roozbehm [at( allenai.org <div style="height:8px;font-size:1px;">&nbsp;</div>
	<a href="https://twitter.com/roozbehmottaghi?lang=en"> <img src="./images/twitter-logo.png" width="30" height="30"> </a> 
	<a href="https://www.semanticscholar.org/author/Roozbeh-Mottaghi/3012475"> <img src="./images/s2-logo.png" width="30" height="30"> </a>
	<a href="https://scholar.google.com/citations?user=CCV58dgAAAAJ&hl=en&oi=ao"> <img src="./images/scholar-logo.jpg" width="30" height="30"> </a>  

	</div>
</div>
</section>


<!-- News -->
<section>
<h2 style="text-align: center">Highlights and News</h2>
<br>
<dl class="dl-horizontal">

  <dt>Feb, 2020:</dt>
  <dd>
    Co-organizing <a href="https://askforalfred.com/EVAL/">Embodied Vision, Actions & Language Workshop</a> at <a href="https://eccv2020.eu/">ECCV 2020</a>, which hosts a challenge on <a href="https://askforalfred.com/">ALFRED</a> our embodied instruction following framework. 
  </dd>

  <dt>Feb, 2020:</dt>
  <dd>
    Co-organizing <a href="https://embodied-ai.org/">Embodied AI Workshop</a> at <a href="http://cvpr2020.thecvf.com/">CVPR 2020</a>. 
  </dd>

  <dt>Feb, 2020:</dt>
  <dd>
    Announcing the RoboTHOR navigation challenge. Follow <a href="https://ai2thor.allenai.org/robothor/challenge/">this link</a> for further information.
  </dd>

  <dt>Nov, 2019:</dt>
  <dd>
    Serving as Area Chair for <a href="http://cvpr2020.thecvf.com/">CVPR 2020</a>.
  </dd>

  <dt>Jun, 2019:</dt>
  <dd>
    Recognized as a <a href="http://cvpr2019.thecvf.com/">CVPR 2019</a> outstanding reviewer.
  </dd>

  <dt>Feb, 2019:</dt>
  <dd>
    Our papers on self-adaptive navigation and knowledge-based question answering have been accepted to <a href="http://cvpr2019.thecvf.com/">CVPR 2019</a>.
  </dd>




</dl>

<a href="news.html">Older items...</a>
</section>

<!-- About Me -->
<section>
<h2 style="text-align: center">About Me</h2>

<p>
I am the Research Manager of the <a href="http://prior.allenai.org">PRIOR</a> team at <a href="http://allenai.org">Allen Institute for AI</a> and an Affiliate Associate Professor in <a href="https://www.cs.washington.edu/">Paul G. Allen School of Computer Science & Engineering</a> at the <a href="https://www.washington.edu/">University of Washington</a>. 
</p>

<p>
Prior to joining AI2, I was a Postdoctoral Researcher in the <a href="http://www.cs.stanford.edu">Computer Science Department</a> at <a href="http://www.stanford.edu">Stanford University</a>. I received a Ph.D. in Computer Science from <a href="http://www.ucla.edu">UCLA</a>, advised by <a href="http://www.cs.jhu.edu/~ayuille/">Alan Yuille</a>. I obtained my Masters degrees from <a href="http://www.sfu.ca">Simon Fraser University</a> and <a href="http://www.gatech.edu">Georgia Institute of Technology</a> and my Bachelors degree from <a href="http://www.en.sharif.edu/">Sharif University of Technology</a>.
</p>

</section>


<!-- 2019 -->
<section>
<A name=pubs></A> <h2 style="text-align: center">Publications</h2>
<ul>

  <li class="paper-with-image">
  <img src="images/cvpr20_a.jpg" width=200 />
  <span>
    <a href="#">RoboTHOR: An Open Simulation-to-Real Embodied AI Platform</a>.<br>

    Matt Deitke*, Winson Han*, Alvaro Herrasti*, Aniruddha Kembhavi*, Eric Kolve*,
    Roozbeh Mottaghi*, Jordi Salvador*, Dustin Schwenk*, Eli VanderBilt*, Matthew Wallingford*, Luca Weihs*, Mark Yatskar*, Ali Farhadi. (* alphabetically listed equal contribution)<br>
    IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2020. <br>  
  </span>
  
  </li>

    <li class="paper-with-image">
  <img src="images/cvpr20_b.png" width=200 />
  <span>
    <a href="https://arxiv.org/pdf/1912.02155.pdf">Visual Reaction: Learning To Play Catch With Your Drone</a>.<br>
    Kuo-Hao Zeng, Roozbeh Mottaghi, Luca Weihs, Ali Farhadi. <br>
    IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2020. <br>
  </span>
  
  </li>

    <li class="paper-with-image">
  <img src="images/cvpr20_c.png" width=200 />
  <span>
    <a href="https://arxiv.org/pdf/1912.01734.pdf">ALFRED: A Benchmark for Interpreting Grounded Instructions for Everyday Tasks</a>.<br>
    Mohit Shridhar, Jesse Thomason, Daniel Gordon, Yonatan Bisk, Winson Han, Roozbeh Mottaghi, Luke Zettlemoyer, Dieter Fox. <br>
    IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2020. <br>
    [<a href="https://askforalfred.com/">Project & Challenge page</a>] 
  </span>
  
  </li>

  <li class="paper-with-image">
  <img src="images/cvpr19_a.png" width=200 />
  <span>
    <a href="https://arxiv.org/pdf/1812.00971.pdf">Learning to Learn How to Learn: Self-Adaptive Visual Navigation using Meta-Learning</a>.<br>
    Mitchell Wortsman, Kiana Ehsani, Mohammad Rastegari, Ali Farhadi, Roozbeh Mottaghi. <br>
    IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2019. <br><b>Oral presentation</b> <br>
    [<a href="https://prior.allenai.org/projects/savn">Project page</a>]    
  </span>
  
  </li>

  <li class="paper-with-image">
  <img src="images/cvpr19_b.png" width=200 />
  <span>
  <a href="https://arxiv.org/pdf/1906.00067.pdf">OK-VQA: A Visual Question Answering Benchmark Requiring External Knowledge</a>.<br>
  Kenneth Marino, Mohammad Rastegari, Ali Farhadi, Roozbeh Mottaghi.<br>
  IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2019. <br>
  [<a href="https://okvqa.allenai.org/">Project page</a>]
  </span>
  </li>

   <li class="paper-with-image">
  <img src="images/iclr19.gif" width=200 />
  <span>
  <a href="https://arxiv.org/pdf/1810.06543.pdf">Visual Semantic Navigation using Scene Priors</a>.<br>
  Wei Yang, Xiaolong Wang, Ali Farhadi, Abhinav Gupta, Roozbeh Mottaghi.<br>
  International Conference on Learning Representations (ICLR), 2019.<br>
  [<a href="https://prior.allenai.org/projects/savn">Project page</a>]
  </span>
  </li>

  <li class="paper-with-image">
  <img src="images/navigation.png" width=200 />
  <span>
  <a href="https://arxiv.org/pdf/1807.06757.pdf">On Evaluation of Embodied Navigation Agents</a>.<br>
  Peter Anderson, Angel Chang, Devendra Singh Chaplot, Alexey Dosovitskiy, Saurabh Gupta, Vladlen Koltun, Jana Kosecka, Jitendra Malik, Roozbeh Mottaghi, Manolis Savva, Amir R. Zamir.<br>
  arXiv, 2018.<br>
  </span>
  </li>

  <li class="paper-with-image">
  <img src="images/cvpr18_a.png" width=200 />
  <span>
  <a href="https://arxiv.org/pdf/1803.10827.pdf">Who Let The Dogs Out? Modeling Dog Behavior From Visual Data</a>.<br>
  Kiana Ehsani, Hessam Bagherinezhad, Joe Redmon, Roozbeh Mottaghi, Ali Farhadi.<br>
  IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2018. <br>
  [<a href="https://github.com/ehsanik/dogTorch">Project page</a>]
  </span>
  </li>

  <li class="paper-with-image">
  <img src="images/cvpr18_b.png" width=200 />
  <span>    
  <a href="https://arxiv.org/pdf/1703.10239.pdf">SeGAN: Segmenting and Generating the Invisible</a>.<br>
  Kiana Ehsani, Roozbeh Mottaghi, Ali Farhadi.<br>
  IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2018. <br><b>Spotlight presentation</b> <br>
  [<a href="https://github.com/ehsanik/SeGAN">Project page</a>]
  </span>
  </li>

  <li class="paper-with-image">
  <img src="images/ai2thor.png" width=200 />
  <span>
  <a href="https://arxiv.org/pdf/1712.05474.pdf">AI2-THOR: An Interactive 3D Environment for Visual AI</a>.<br>
  Eric Kolve, Roozbeh Mottaghi, Winson Han, Eli VanderBilt, Luca Weihs, Alvaro Herrasti, Daniel Gordon, Yuke Zhu, Abhinav Gupta, Ali Farhadi.<br>
  arXiv, 2017.<br>
  [<a href="http://ai2thor.allenai.org/">http://ai2thor.allenai.org/</a>]
  </span>
  </li>

  <li class="paper-with-image">
  <img src="images/iccv17_a.png" width=200 />
  <span>
  <a href="https://arxiv.org/pdf/1705.08080.pdf">Visual Semantic Planning using Deep Successor Representations</a>.<br>
  Yuke Zhu*, Daniel Gordon*, Eric Kolve, Dieter Fox, Li Fei-Fei, Abhinav Gupta, Roozbeh Mottaghi, Ali Farhadi.<br>
  International Conference on Computer Vision (ICCV), 2017.<br>
  [<a href="https://prior.allenai.org/projects/visual-semantic-planning">Project page</a>]
  </span>
  </li>

  <li class="paper-with-image">
  <img src="images/iccv17_b.png" width=200 />
  <span>
  <a href="https://arxiv.org/pdf/1701.02718.pdf">See the Glass Half Full: Reasoning about Liquid Containers, their Volume and Content</a>.<br>
  Roozbeh Mottaghi, Connor Schenck, Dieter Fox, Ali Farhadi.<br>
  International Conference on Computer Vision (ICCV), 2017.<br>
  [<a href="https://prior.allenai.org/projects/see-the-glass-half-full">Project page</a>]
  </span>
  </li>  

  
  <li class="paper-with-image">
  <img src="images/icra17.png" width=200 />
  <span>
  <a href="https://arxiv.org/pdf/1609.05143.pdf">Target-driven Visual Navigation in Indoor Scenes using Deep Reinforcement Learning</a>.<br>
  Yuke Zhu, Roozbeh Mottaghi, Eric Kolve, Joseph J. Lim, Abhinav Gupta, Li Fei-Fei, and Ali Farhadi.<br>
  International Conference on Robotics and Automation (ICRA), 2017.<br>
  [<a href="https://prior.allenai.org/projects/target-driven-visual-navigation">Project page</a>]
  </span>
  </li>  

  <li class="paper-with-image">
  <img src="images/eccv16_a.png" width=200 />
  <span>
  <a href="https://arxiv.org/pdf/1603.05600.pdf">"What happens if..." Learning to Predict the Effect of Forces in Images</a>.<br>
  Roozbeh Mottaghi, Mohammad Rastegari, Abhinav Gupta, Ali Farhadi.<br>
  European Conference on Computer Vision (ECCV), 2016.<br>
  [<a href="https://prior.allenai.org/projects/what-happens-if">Project page</a>]
  </span>
  </li>  

  <li class="paper-with-image">
  <img src="images/eccv16_b.png" width=200 />
  <span>
  <a href="papers/Xiang16eccv.pdf">ObjectNet3D: A Large Scale Database for 3D Object Recognition</a>.<br>
  Yu Xiang, Wonhui Kim, Wei Chen, Jingwei Ji, Christopher Choy, Hao Su, Roozbeh Mottaghi, Leonidas Guibas, Silvio  Savarese.<br>
  European Conference on Computer Vision (ECCV), 2016.  <br><b>Spotlight presentation</b><br>
  [<a href="http://cvgl.stanford.edu/projects/objectnet3d/">Project page</a>]
  </span>
  </li>  

  <li class="paper-with-image">
  <img src="images/cvpr16_a.png" width=200 />
  <span>
  <a href="papers/Mottaghi16cvpr_a.pdf">Newtonian Image Understanding: Unfolding the Dynamics of Objects in Static Images</a>.<br>
    Roozbeh Mottaghi, Hessam Bagherinezhad, Mohammad Rastegari, Ali Farhadi.<br>
    IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2016.  <br>
    [<a href="https://prior.allenai.org/projects/newtonian-image-understanding">Project page</a>]
  </li> 

  <li class="paper-with-image">
  <img src="images/cvpr16_b.png" width=200 />
  <span>
  <a href="papers/Mottaghi16cvpr_b.pdf">A Task-oriented Approach for Cost-sensitive Recognition</a>.<br>
    Roozbeh Mottaghi, Hannaneh Hajishirzi, Ali Farhadi.<br>
    IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2016.  <br>
    [<a href="https://prior.allenai.org/projects/task-oriented">Project page</a>][<a href="papers/Mottaghi16cvpr_b-sm.pdf">Supplementary Material</a>]
  </span>
  </li> 

  <li class="paper-with-image">
  <img src="images/pami15.png" width=200 />
  <span>
  <a href="papers/Mottaghi16pami.pdf">Human-Machine CRFs for Identifying Bottlenecks in Scene Understanding</a>.<br>
    Roozbeh Mottaghi, Sanja Fidler, Alan Yuille, Raquel Urtasun, Devi Parikh.<br>
    IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), 38(1):74-87, 2016.<br>
    [<a href="papers/Mottaghi16pami-sm.pdf">Supplementary Material</a>]
  </span>    
  </li> 

  <li class="paper-with-image">
  <img src="images/jmlr15.png" width=200 />
  <span>
  <a href="http://jmlr.org/papers/v17/yuille16a.html">Complexity of Representation and Inference in Compositional Models with Part Sharing</a>.<br>
    Alan Yuille and Roozbeh Mottaghi.<br>
    Journal of Machine Learning Research (JMLR), 17(11):1-28, 2016.<br>
  </span>    
  </li> 

  <li class="paper-with-image">
  <img src="images/cvpr15.png" width=200 />
  <span>
  <a href="papers/Mottaghi15cvpr.pdf">A Coarse-to-Fine Model for 3D Pose Estimation and Sub-category Recognition</a>.<br>
    Roozbeh Mottaghi, Yu Xiang, and Silvio Savarese. <br>
    IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2015.<br>
    [<a href="papers/Mottaghi15cvpr-sm.pdf">Supplementary Material</a>][<A href="ftp://cs.stanford.edu/cs/cvgl/cvpr_15_annotation.tar.gz">dataset</A>][<A href="ftp://cs.stanford.edu/cs/cvgl/cad_models_cvpr15.tar.gz">CAD models</A>]
  </span>    
  </li> 

  <li class="paper-with-image">
  <img src="images/eccv14.png" width=200 />
  <span>
  <a href="papers/Xiang14eccv.pdf">Monocular Multiview Object Tracking with 3D Aspect Parts</a>.<br>
    Yu Xiang*, Changkyu Song*, Roozbeh Mottaghi and Silvio Savarese.<br>
    European Conference on Computer Vision (ECCV), 2014.<br>
  </span>    
  </li> 

  <li class="paper-with-image">
  <img src="images/wacv14.png" width=200 />
  <span>
  <a href="papers/Xiang14wacv.pdf">Beyond PASCAL: A Benchmark for 3D Object Detection in the Wild</a>.<br>
    Yu Xiang, Roozbeh Mottaghi, and Silvio Savarese.<br>
    IEEE Winter Conference on Applications of Computer Vision (WACV), 2014.<br>
    [<A href="http://cvgl.stanford.edu/projects/pascal3d.html">PASCAL 3D+ dataset</A>]
  </span>    
  </li> 

  <li class="paper-with-image">
  <img src="images/cvpr14_a.png" width=200 />
  <span>
  <a href="papers/Mottaghi14cvpr.pdf">The Role of Context for Object Detection and Semantic Segmentation in the Wild</a>.<br>
    Roozbeh Mottaghi, Xianjie Chen, Xiaobai Liu, Nam-Gyu Cho, Seong-Whan Lee, Sanja Fidler, Raquel Urtasun, Alan Yuille.<br>
    IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2014.<br>
    [<A href="papers/errata.pdf">Errata</A>][<A href="pascal-context/">PASCAL Context dataset</A>]
  </span>    
  </li> 

  <li class="paper-with-image">
  <img src="images/cvpr14_b.png" width=200 />
  <span>
  <a href="papers/Chen14cvpr.pdf">Detect What You Can: Detecting and Representing Objects using Holistic Models and Body Parts</a>.<br>
    Xianjie Chen, Roozbeh Mottaghi, Xiaobai Liu, Sanja Fidler, Raquel Urtasun, Alan Yuille.<br>
    IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2014.<br>
    [<A href="pascal-parts/pascal-parts.html">PASCAL Parts dataset</A>]
  </span>    
  </li> 

  <li class="paper-with-image">
  <img src="images/iclr13.png" width=200 />
  <span>
  <a href="http://arxiv.org/abs/1301.3560">Complexity of Representation and Inference in Compositional Models with Part Sharing</a>.<br> 
    Alan Yuille and Roozbeh Mottaghi.<br>
    International Conference on Learning Representations (ICLR), 2013. <br><b>Oral presentation</b><br>
  </span>    
  </li> 

  <li class="paper-with-image">
  <img src="images/cvpr13_a.png" width=200 />
  <span>
  <a href="papers/Mottaghi13cvpr_a.pdf">Analyzing Semantic Segmentation Using Hybrid Human-Machine CRFs</a>.<br> 
    Roozbeh Mottaghi, Sanja Fidler, Jian Yao, Raquel Urtasun, Devi Parikh.<br>
    IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2013. <br>
    [<A href="papers/Mottaghi13cvpr_a-sm.pdf">Supplementary material</A>]
  </span>    
  </li> 

  <li class="paper-with-image">
  <img src="images/cvpr13_b.png" width=200 />
  <span>
  <a href="papers/Fidler13cvpr.pdf">Bottom-up Segmentation for Top-down Detection</a>.<br> 
    Sanja Fidler, Roozbeh Mottaghi, Alan Yuille, Raquel Urtasun.<br>
    IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2013. <br>
    [<A href="https://www.cs.utoronto.ca/~fidler/projects/segDPM.html">Project page</A>]
  </span>    
  </li> 

  <li class="paper-with-image">
  <img src="images/cvpr12.png" width=200 />
  <span>
  <a href="papers/Mottaghi12cvpr.pdf">Augmenting Deformable Part Models with Irregular-shaped Object Patches</a>.<br> 
    Roozbeh Mottaghi.<br>
    IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2012. <br>
    [<A href="papers/Mottaghi12cvpr-sm.pdf">Supplementary material</A>]
  </span>    
  </li> 

  <li class="paper-with-image">
  <img src="images/iccvw11.png" width=200 />
  <span>
  <a href="papers/Mottaghi11iccvw.pdf">A Compositional Approach to Learning Part-based Models of Objects</a>.<br> 
    Roozbeh Mottaghi, Ananth Ranganathan, and Alan Yuille.<br>
    Workshop on 3D Representation and Recognition, held with the International Conference on Computer Vision (ICCV), 2011. <br>
    [<A href="misc/HOGBundle.tar.gz">Code</A>]
  </span>    
  </li>   

  <li class="paper-with-image">
  <img src="images/icra09.jpg" width=200 />
  <span>
  <a href="papers/Lee09icra.pdf">Graph-based Planning Using Local Information for Unknown Outdoor Environments</a>.<br> 
    Jinhan Lee, Roozbeh Mottaghi, Charles Pippin, and Tucker Balch.<br>
    International Conference on Robotics and Automation (ICRA), 2009. <br>
  </span>    
  </li>   

  <li class="paper-with-image">
  <img src="images/icra08.jpg" width=200 />
  <span>
  <a href="papers/Mottaghi08icra.pdf">Place Recognition-based Fixed-lag Smoothing for Environments with Unreliable GPS</a>.<br> 
    Roozbeh Mottaghi, Michael Kaess, Ananth Ranganathan, Richard Roberts, and Frank Dellaert.<br>
    International Conference on Robotics and Automation (ICRA), 2008. <br>
    [<A href="movies/placerec.mp4">Video</A>]
  </span>    
  </li>   

  <li class="paper-with-image">
  <img src="images/autorob.jpg" width=200 />
  <span>
  <a href="papers/Mottaghi07autorob.pdf">An Integrated Particle Filter and Potential Field Method Applied to Multi-Robot Target Tracking</a>.<br> 
    Roozbeh Mottaghi and Richard Vaughan.<br>
    Autonomous Robots, 23(1):19-35, 2007. <br>
    [Videos: <A href="movies/tworec.mp4">clip 1</A> and <A href="movies/4ro-3.avi">clip 2</A>]
  </span>    
  </li>   

  <li class="paper-with-image">
  <img src="images/icra06.jpg" width=200 />
  <span>
  <a href="papers/Mottaghi06icra.pdf">An Integrated Particle Filter & Potential Field Method for Cooperative Robot Target Tracking</a>.<br> 
    Roozbeh Mottaghi and Richard Vaughan.<br>
    International Conference on Robotics and Automation (ICRA), 2006. <br>    
  </span>    
  </li>   

  <li class="paper-with-image">
  <img src="images/icar05.jpg" width=200 />
  <span>
  <a href="papers/Mottaghi05icar.pdf">An Overview of a Probabilistic Tracker for Multiple Cooperative Tracking Agents</a>.<br> 
    Roozbeh Mottaghi and Shahram Payandeh.<br>
    International Conference on Advanced Robotics (ICAR), 2005. <br>    
  </span>    
  </li>   

  <li class="paper-with-image">
  <img src="images/crv05.jpg" width=200 />
  <span>
  <a href="papers/Mottaghi05crv.pdf">Coordination of Multiple Agents for Probabilistic Object Tracking</a>.<br> 
    Roozbeh Mottaghi and Shahram Payandeh.<br>
    Canadian Conference on Computer and Robot Vision (CRV), 2005. <br>    
  </span>    
  </li>   

  <li class="paper-with-image">
  <img src="images/robocup.jpg" width=200 />
  <span>
  <a href="papers/Manzuri02LNAI.pdf">SharifCESR Small Size Robocup Team</a>.<br> 
    Mohammad T. Manzuri, Hamid R. Chitsaz, Reza Ghorbani, Pooya Karimian, Alireza Mirazi, Mehran Motamed, Roozbeh Mottaghi and Payam Sabzmeydani.<br>
    Robocup 2001: Robot Soccer World Cup V. Lecture Notes in Artificial Intelligence 2377, 2012. <br>    
  </span>    
  </li>   
</ul>

</section>


<!-- Press -->
<section>
<h2 style="text-align: center">Press Coverage</h2>

<ul>

  <li>
  <i>RoboTHOR Challenge</i>.<br>
  
  <table style="text-align: center; width: 100px;" border="0" cellpadding="0" cellspacing="3">
  <tbody>
  <tr>

  <td>
    <a href="https://www.geekwire.com/tag/robothor-challenge/">
    <img style="border:2px solid gray; padding:2px; width: 137px; height: 30px;" src="./images/GeekWire-logo.png">
    </a>
  </td>

  <td>
    <a href="https://www.technologyreview.com/s/615186/ai-ai2-robots-navigate-world-train-algorithms-challenge/">
    <img style="border:2px solid gray; padding:2px; width: 70px; height: 30px;" src="./images/mit-tech-review-logo.png">
    </a>
  </td>


  </tr>
  </tbody>
  </table>
  </li>

  <li>
  <i>AI2-THOR Project</i>.<br>
  
  <table style="text-align: center; width: 100px;" border="0" cellpadding="0" cellspacing="3">
  <tbody>
  <tr>

  <td>
    <a href="https://spectrum.ieee.org/tech-talk/robotics/artificial-intelligence/interactive-simulation-teaches-ai-about-real-world">
    <img style="border:2px solid gray; padding:2px; width: 150px; height: 30px;" src="./images/ieee-spectrum-logo.jpg">
    </a>
  </td>

  <td>
    <a href="https://www.digitaltrends.com/cool-tech/virtual-reality-training-for-robots/">
    <img style="border:2px solid gray; padding:2px; width: 197px; height: 30px;" src="./images/DT-logo.png">
    </a>
  </td>

  <td>
    <a href="https://www.cbc.ca/news/technology/ramona-pringle-robot-butler-fears-1.4567516">
    <img style="border:2px solid gray; padding:2px; width: 59px; height: 30px;" src="./images/cbc-logo.jpg">
    </a>
  </td>

  </tr>
  </tbody>
  </table>
  </li>

  <li>
  <i>Dog Project</i>.
  
  <table style="text-align: center; width: 100px;" border="0" cellpadding="0" cellspacing="3">
  <tbody>
  <tr>

  <td>
    <a href="https://techcrunch.com/2018/04/11/whos-a-good-ai-dog-based-data-creates-a-canine-machine-learning-system/">
    <img style="border:2px solid gray; padding:2px; width: 208px; height: 30px;" src="./images/techcrunch-logo.png">
    </a>
  </td>

  <td>
    <a href="https://www.technologyreview.com/s/610775/this-ai-thinks-like-a-dog/">
    <img style="border:2px solid gray; padding:2px; width: 70px; height: 30px;" src="./images/mit-tech-review-logo.png">
    </a>
  </td>

  <td>
    <a href="http://www.pbs.org/wgbh/nova/next/tech/ai-trained-to-act-like-a-dog/">
    <img style="border:2px solid gray; padding:2px; width: 75px; height: 30px;" src="./images/PBS_logo.png">
    </a>
  </td>

  <td>
    <a href="https://www.theverge.com/2018/4/14/17234570/artificial-intelligence-dogs-research-science-learning">
    <img style="border:2px solid gray; padding:2px; width: 58px; height: 30px;" src="./images/verge-logo.png">
    </a>
  </td>

  <td>
    <a href="https://spectrum.ieee.org/tech-talk/robotics/artificial-intelligence/real-dog-behavior-could-inspire-robot-dogs">
    <img style="border:2px solid gray; padding:2px; width: 150px; height: 30px;" src="./images/ieee-spectrum-logo.jpg">
    </a>
  </td>  

  <td>
    <a href="https://www.nbcnews.com/mach/science/why-scientists-are-teaching-ai-think-dog-ncna869266">
    <img style="border:2px solid gray; padding:2px; width: 37px; height: 30px;" src="./images/nbc-logo.png">
    </a>
  </td>    

  <td>
    <a href="http://www.euronews.com/2018/04/26/why-scientists-are-teaching-ai-think-dog-ncna869266">
    <img style="border:2px solid gray; padding:2px; width: 114px; height: 30px;" src="./images/euronews-logo.png">
    </a>
  </td>    

  <td>
    <a href="https://www.reuters.com/video/2018/06/14/dog-vision-project-analyses-canine-behav?videoId=435834651&videoChannel=118065&channelName=Moments+of+Innovation">
    <img style="border:2px solid gray; padding:2px; width: 29px; height: 30px;" src="./images/Reuters-Logo.jpg">
    </a>
  </td> 

  </tr>
  </tbody>
  </table>
  </li>


  <li>
  <i>Prediction Project</i>.<br>
  
  <table style="text-align: center; width: 100px;" border="0" cellpadding="0" cellspacing="3">
  <tbody>
  <tr>

  <td>
    <a href="https://www.technologyreview.com/s/602246/what-robots-can-learn-from-babies/">
    <img style="border:2px solid gray; padding:2px; width: 70px; height: 30px;" src="./images/mit-tech-review-logo.png">
    </a>
  </td>

  </tr>
  </tbody>
  </table>
  </li>

  <li>
  <i>AI documentary (Can we build a brain?)</i><br>
  
  <table style="text-align: center; width: 100px;" border="0" cellpadding="0" cellspacing="3">
  <tbody>
  <tr>

  <td>
    <a href="https://www.pbs.org/video/nova-wonders-can-we-build-a-brain-j53aqg/">
    <img style="border:2px solid gray; padding:2px; width: 75px; height: 30px;" src="./images/PBS_logo.png">
    </a>
  </td>

  </tr>
  </tbody>
  </table>
  </li>


</ul>

<br>
</section>



<!-- Footer -->
<footer>
<h4>© Roozbeh Mottaghi</h4>
<h6>(Adopted the template from <a href="https://www.cc.gatech.edu/~dbatra/">Dhruv Batra</a>'s website)</h6>
</footer>

<!-- Start of StatCounter Code -->
<script type="text/javascript" language="javascript">
var sc_project=1498370; 
var sc_invisible=1; 
var sc_partition=13; 
var sc_security="250b5be7"; 
</script>

<script type="text/javascript" language="javascript" src="https://www.statcounter.com/counter/counter.js"></script><noscript><a href="https://www.statcounter.com/" target="_blank"><img  src="https://c14.statcounter.com/counter.php?sc_project=1498370&amp;java=0&amp;security=250b5be7&amp;invisible=1" alt="free stats" border="0"></a> </noscript>
<!-- End of StatCounter Code -->


</body></html>
